# üõ†Ô∏è Are Copilots Local Yet?

The current state of using local LLM models as copilots to complete code, generate projects, act as shell assistants, automatically fix bugs, and more.

üìù *Help keep this list relevant and up-to-date by [making edits][edit]!*

[edit]: https://github.com/ErikBjare/are-copilots-local-yet/edit/master/README.md

## üìã Summary

Local Copilots are in an early experimental stage, with most being of MVP-quality. 

The reasons for this are:

- üìâ Local models still being inferior to Copilot
- üîß Difficult to set up
- üíª High hardware requirements

However, as models improve, and editor extensions get developed to use them, we're expected to get a renaissance of code-completion tools.

This document is a curated list of local Copilots, shell assistants, and related projects. It is intended to be a resource for those interested in a survey of the existing tools, and to help developers discover the state of the art for projects like these.

## üìö Background

In 2021, GitHub released Copilot which quickly became popular among devs. Since then, with the flurry of AI developments around LLMs, local models that can run on consumer machines have become available, and it has seemed only a matter of time before Copilot will go local.

Many perceived limitations of GitHub's Copilot are related to its closed and cloud-hosted nature. 

As an alternative, local Copilots enable:

- üåê Offline & private use
- ‚ö° Improved responsiveness
- üìö Better project/context awareness
- üéØ The ability to run models specialized for a particular language/task
- üîí [Constraining the LLM output](https://twitter.com/ErikBjare/status/1656731582001020928) to fit a particular format/syntax.

## üß© Extensions

Editor extensions used to complete code using LLMs:

| Name        | Editor | Stars | Notes   |
|-------------|--------|-------|---------|
| [Fauxpilot][fauxpilot]   | VSCode | >12k  | Stale?  |
| [Tabby][tabby] | VSCode | >8k | Completes the cursor selection  |
| [HuggingFace-vscode][hf-vscode] | VSCode | >300  | Fork of Tabnine, supports Starcoder |
| [StarcoderEx][sc-ex] | VSCode | >60   | Completes the cursor selection |
| [WizardCoder-VSC][wc-vsc] | VSCode | >50   | PoC, [article][wc-vsc-blog] |
| [turbopilot][turbopilot] | VSCode | >3.8k |      |

[fauxpilot]: https://github.com/fauxpilot/fauxpilot
[tabby]: https://github.com/TabbyML/tabby
[hf-vscode]: https://github.com/huggingface/huggingface-vscode
[sc-ex]: https://github.com/Lisoveliy/StarCoderEx
[wc-vsc]: https://github.com/mzbac/wizardCoder-vsc
[wc-vsc-blog]: https://medium.com/@anchen.li/build-your-own-copliot-using-open-source-llm-ff9da556cb09
[turbopilot]: https://github.com/ravenscroftj/turbopilot

## üõ†Ô∏è Tools

Tools that try to generate projects/features from specification:

| Name         | Stars | Notes   |
|--------------|-------|---------|
| [gpt-engineer][gpt-engineer] | >42k  |         |
| [continue][continue]     | >4k   |         |
| [rift][rift]         | >2.5k | VSCode extension |
| [mentat][mentat]       | >1.5k |         |
| [clippinator][clippinator]  | >200  | Uses a team of agents to plan, write, debug, and test |

[gpt-engineer]: https://github.com/AntonOsika/gpt-engineer
[continue]: https://github.com/continuedev/continue
[rift]: https://github.com/morph-labs/rift
[mentat]: https://github.com/biobootloader/mentat
[clippinator]: https://github.com/ennucore/clippinator

## üó®Ô∏è Chat Interfaces

Chat interfaces with shell access:

| Name         | Stars | Notes   |
|--------------|-------|---------|
| [open-interpreter][oi] | >14.3k  |         |
| [gptme][gptme] | >80 | Developed by me, @ErikBjare |
| [terminal-x][terminal-x] | >30 | Very early prototype that converts natural language into shell commands, unmaintained since Sept. 2021 |

[oi]: https://github.com/KillianLucas/open-interpreter
[gptme]: https://github.com/ErikBjare/gptme
[terminal-x]: https://github.com/davidfant/terminal-x

## ü§ñ Models

Models relevant for local Copilot-use:

| Name        | Size | Languages | Stars | Released | Notes |
|-------------|------|-----------|-------|----------|-------|
| [codellama][codellama]   | 7/13/34B | ?        | >2.7k   | 2023-8  | |
| [Starcoder][starcoder]   | 15B | 80+        | >5k   | 2023-5  |       |
| [WizardCoder-Python][wc-py] | 7/13/34B | Python | >500 | 2023-8 | |
| [WizardCoder][wc-v1] | 15B | 80+        | >390  | 2023-6  | Fine-tuning of Starcoder |
| [replit-v1-3b][replit-v1] | 3B | 20+        | >600  | 2023-5  |      |
| [replit-glaive][replit-glaive] | 3B | 1?        | >70   | 2023-7  | Small model fine-tuned on high-quality data, with impressive performance. |

[codellama]: https://github.com/facebookresearch/codellama
[starcoder]: https://github.com/bigcode-project/starcoder
[wc-py]: https://huggingface.co/WizardLM/WizardCoder-Python-34B-V1.0
[wc-v1]: https://huggingface.co/WizardLM/WizardCoder-15B-V1.0
[replit-v1]: https://huggingface.co/replit/replit-code-v1-3b
[replit-glaive]: https://huggingface.co/sahil2801/replit-code-instruct-glaive

## üì∞ Misc

- üê¶ [Tweet announcing this repo][announce]

[announce]: https://twitter.com/ErikBjare/status/1681616666600394753
